{"cells":[{"cell_type":"markdown","id":"a6478d78-9ea9-4096-8210-f120f3e97b07","metadata":{"id":"a6478d78-9ea9-4096-8210-f120f3e97b07"},"source":["# In this snippet we will learn about different components of CNN"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"38Z-FxflyvGA"},"id":"38Z-FxflyvGA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"658fd5b8-33cd-44dd-8757-8e3ccab5fa06","metadata":{"id":"658fd5b8-33cd-44dd-8757-8e3ccab5fa06"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","seed = 7777\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","id":"65e1e5ff-730a-438f-ab4a-0815293de11f","metadata":{"id":"65e1e5ff-730a-438f-ab4a-0815293de11f"},"source":["## Linear layer\n","\n","<div style=\"text-align: justify\">\n","A Linear layer (also known as fully connected layer or dense layer) is the simplest layer for CNN. This Layer in a Convolutional Neural Network (CNN) is like a mathematical function that transforms input data into output data. It changes the shape of the input data. It's like a set of weights (coefficients) connecting every neuron in one layer to every neuron in the next layer. For example, in image classification, if the input is a flattened image array (say, 28x28 pixels), and you want to classify it into 10 categories, you'd use a Linear Layer with 28x28 inputs and 10 outputs. Each output represents the confidence score for each category. Through training, the network adjusts these weights to improve accuracy.\n","</div>\n","\n","![Linear layer](images/Linear.png)"]},{"cell_type":"code","execution_count":null,"id":"ac9b43c7-0fcb-4ecc-b8cf-d7f4521f880e","metadata":{"id":"ac9b43c7-0fcb-4ecc-b8cf-d7f4521f880e"},"outputs":[],"source":["Linear = nn.Linear(5,8).to(device)\n","x = torch.tensor([5.,2,3,1,2]).to(device)\n","y = Linear(x)\n","x = x.cpu().detach().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n',end='\\n\\n')\n","\n","x = torch.rand(64,5).to(device)\n","y = Linear(x)\n","print(f'Input Shape: {np.array(x.shape)}',f'Output Shape: {y.shape}',sep='\\n')"]},{"cell_type":"markdown","id":"ab2528b1-5c41-4f03-9730-4b6a3324f4ef","metadata":{"id":"ab2528b1-5c41-4f03-9730-4b6a3324f4ef"},"source":["### Stacked Linear layer\n","\n","<div style=\"text-align: justify\">\n","In a neural network, stacked linear layers are fundamental components for transforming input data into meaningful output. Each layer, implemented with Linear transformation, takes input from the preceding layer, performs a linear operation (matrix multiplication), and passes it through a non-linear activation function to capture complex relationships within the data. Stacking multiple layers allows the network to learn increasingly abstract features, with dimensions typically decreasing towards the output layer. This hierarchical representation facilitates the network's ability to comprehend and classify complex patterns within the data. Stacked linear layers are more effective than a single linear layer when dealing with complex and nonlinear relationships within the data. By stacking multiple layers, each equipped with its own set of parameters, the network gains the capacity to learn hierarchical representations of the input features. This enables the model to capture intricate patterns and dependencies that may not be discernible with just a single linear transformation. Additionally, the introduction of nonlinear activation functions between layers allows for the modeling of nonlinear relationships, enhancing the network's flexibility and ability to approximate complex functions effectively. Therefore, stacked linear layers are particularly beneficial in scenarios where the data exhibits nonlinear behavior or requires multiple levels of abstraction for accurate modeling.\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"ef94d3a4-33ff-4f2f-9d4f-b93cce82efea","metadata":{"id":"ef94d3a4-33ff-4f2f-9d4f-b93cce82efea"},"outputs":[],"source":["fc1 = nn.Linear(256,80).to(device)\n","fc2 = nn.Linear(80,40).to(device)\n","fc3 = nn.Linear(40,20).to(device)\n","x = torch.rand(64,256).to(device)\n","\n","print(list(x.shape))\n","y1 = fc1(x)\n","print(list(x.shape),'---->',list(y1.shape))\n","y2 = fc2(y1)\n","print(list(y1.shape),'---->',list(y2.shape))\n","y3 = fc3(y2)\n","print(list(y2.shape),'---->',list(y3.shape))"]},{"cell_type":"code","execution_count":null,"id":"ac016cd7-9a4b-4aa6-9d15-b9cbf7dd61f9","metadata":{"id":"ac016cd7-9a4b-4aa6-9d15-b9cbf7dd61f9"},"outputs":[],"source":["fc = nn.Sequential(nn.Linear(256,80), nn.Linear(80,40), nn.Linear(40,20)).to(device)\n","x = torch.rand(64,256).to(device)\n","y = fc(x)\n","print(list(x.shape),'---->',list(y.shape))"]},{"cell_type":"markdown","id":"7503bcc4-8d95-4b50-ae0d-cb6f9208029b","metadata":{"id":"7503bcc4-8d95-4b50-ae0d-cb6f9208029b"},"source":["### Linear layer after addition of different features\n","\n","<div style=\"text-align: justify\">\n","Combining distinct features before passing them through a Linear layer enhances the model's capability to capture multifaceted relationships within the data. By concatenating or adding these features, the network gains access to a richer representation of the input, potentially improving its predictive power. The Linear layer then processes this combined feature representation by performing a linear transformation, adjusting the weights associated with each feature to generate output predictions. This approach leverages the complementary nature of diverse features, empowering the model to make more informed and accurate decisions. A typical example could be adding image feature with output of LSTM for predicting the next word in image captioning.\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"7c7feba7-3e84-4e9c-b887-23b522a0380b","metadata":{"id":"7c7feba7-3e84-4e9c-b887-23b522a0380b"},"outputs":[],"source":["fc = nn.Linear(256,256).to(device)\n","x = torch.rand(64,256).to(device)\n","y = torch.rand(64,256).to(device)\n","print(list(x.shape),list(y.shape))\n","z = x+y\n","print(f'{list(x.shape)} + {list(y.shape)} ----> {list(z.shape)}')\n","o = fc(z)\n","print(list(z.shape),list(o.shape))"]},{"cell_type":"markdown","id":"e4e06641-6718-4639-83ce-2d6120fd485d","metadata":{"id":"e4e06641-6718-4639-83ce-2d6120fd485d"},"source":["## Pooling layer\n","\n","<div style=\"text-align: justify\">\n","Pooling layers in neural networks reduce the spatial dimensions (width and height) of the input volume, effectively downsampling it. By aggregating information from neighboring pixels or units, pooling layers help in capturing the most important features while reducing computational complexity. This downsampling also aids in making the network more robust to variations in input, providing a form of translation invariance. Typically, pooling is performed with a sliding window over the input, where each operation (like taking the maximum or average value) is applied over a fixed-size region, resulting in a smaller output volume.\n","</div>\n","\n","![Pooling layer](images/Pooling.png)"]},{"cell_type":"markdown","id":"6e96a1ec-393a-407e-a0fc-4640aa037e67","metadata":{"id":"6e96a1ec-393a-407e-a0fc-4640aa037e67"},"source":["## Components of Pooling layer\n","\n","<div style=\"text-align: justify\">\n","Pooling operations have three key components:<br>\n","<b>1. Window Size/Kernel Size:</b> This refers to the size of the sliding window that moves across the input volume during pooling. It determines the region over which the pooling operation (e.g., max or average) is applied.<br>\n","<b>2. Padding:</b> Padding is an optional component in pooling layers. It involves adding additional pixels around the input feature map. Padding can be used to control the spatial dimensions of the output feature map. Common padding techniques include <strong>zero padding</strong>, where all zeros are added for padding.<br>\n","<b>3. Stride:</b> Stride refers to the number of pixels the pooling window moves across the input feature map in each step. A larger stride reduces the spatial dimensions of the output feature map.<br>\n","The formula for obtaining the output size <strong>f</strong> when applying pooling with a window size of <strong>w</strong>, a stride size of <strong>s</strong>, and padding size of <strong>p</strong> to an input of size <strong>i</strong> is expressed as:<br>\n","$$\n","  f = \\left\\lfloor\\frac{i + 2 \\times p - w}{s}\\right\\rfloor + 1\n","$$\n","</div>\n","\n","## Types of Pooling layer\n","\n","<div style=\"text-align: justify\">\n","Some common poolings are as follows:<br>\n","<b>Maxpool:</b> Pool the maximum element in the window<br>\n","</div>\n","\n","![Maxpool](images/Maxpool.png)\n","\n","<b>Avgpool:</b> Pool the average of all the elements in the window<br>\n","</div>\n","\n","![Avgpool](images/Avgpool.png)"]},{"cell_type":"code","execution_count":null,"id":"34562547-5c44-4440-9c7e-658513f1635a","metadata":{"id":"34562547-5c44-4440-9c7e-658513f1635a"},"outputs":[],"source":["# Define max pooling layer\n","max_pool = nn.MaxPool2d(kernel_size=2, stride=2).to(device)\n","\n","# Example input tensor (batch_size, channels, length)\n","x = torch.tensor([[[1., 2,3,4,5,6],[7,8,9,10,11,12],[13,14,15,16,17,18],[19,20,21,22,23,24]]]).to(device)\n","# Apply max pooling\n","y = max_pool(x)\n","x = x.cpu().detach().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","print('Shape of input tensor is: ',list(x.squeeze().shape))\n","print('Shape of output tensor is: ',list(y.squeeze().shape))"]},{"cell_type":"code","execution_count":null,"id":"8d0b4379-2b05-4398-ab1b-a3d5e311aad5","metadata":{"id":"8d0b4379-2b05-4398-ab1b-a3d5e311aad5"},"outputs":[],"source":["# Define max pooling layer\n","max_pool = nn.MaxPool2d(kernel_size=3, stride=1).to(device)\n","\n","# Example input tensor (batch_size, channels, length)\n","x = torch.tensor([[[1., 2,3,4,5,6],[7,8,9,10,11,12],[13,14,15,16,17,18],[19,20,21,22,23,24]]]).to(device)\n","# Apply max pooling\n","y = max_pool(x)\n","x = x.cpu().detach().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","print('Shape of input tensor is: ',list(x.squeeze().shape))\n","print('Shape of output tensor is: ',list(y.squeeze().shape))"]},{"cell_type":"code","execution_count":null,"id":"151a2ff3-08c8-49a2-8fe5-c1ccb5c01d72","metadata":{"id":"151a2ff3-08c8-49a2-8fe5-c1ccb5c01d72"},"outputs":[],"source":["# Define max pooling layer\n","max_pool = nn.AvgPool2d(kernel_size=2, stride=2).to(device)\n","\n","# Example input tensor (batch_size, channels, length)\n","x = torch.tensor([[[1.,2,3,4,5,6],[7,8,9,10,11,12],[13,14,15,16,17,18],[19,20,21,22,23,24]]]).to(device)\n","# Apply max pooling\n","y = max_pool(x)\n","x = x.cpu().detach().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","print('Shape of input tensor is: ',list(x.squeeze().shape))\n","print('Shape of output tensor is: ',list(y.squeeze().shape))"]},{"cell_type":"markdown","id":"c0411545-0992-43d8-8aca-520517f01620","metadata":{"id":"c0411545-0992-43d8-8aca-520517f01620"},"source":["## Convolution layer\n","\n","<div style=\"text-align: justify\">\n","In Convolutional Neural Networks (CNNs), convolutional operations are fundamental for feature extraction. It involves applying a filter (also known as a kernel) over an input image or feature map to compute a weighted sum of the pixel values. The filter slides over the input, multiplying its values element-wise with the overlapping region of the input and summing up the results to produce a single output value. This process captures spatial hierarchies of features, such as edges and textures, by detecting patterns at different locations. Through repeated convolutions with multiple filters, CNNs can learn hierarchical representations, starting from simple features like edges in lower layers to complex patterns like object parts in deeper layers. Convolutional operations offer two main advantages: parameter sharing and spatial invariance. Parameter sharing ensures that the same filter is applied across the entire input, reducing the number of parameters to learn. Spatial invariance allows CNNs to recognize patterns regardless of their location in the input, making them effective for tasks like image recognition, object detection, and semantic segmentation. Overall, convolutional operations are crucial for enabling CNNs to learn meaningful representations from raw input data.\n","</div>\n","\n","![Convolution layer](images/Convolution.png)"]},{"cell_type":"code","execution_count":null,"id":"188caaa2-016d-4d94-be2a-ea8c35d28ea0","metadata":{"id":"188caaa2-016d-4d94-be2a-ea8c35d28ea0"},"outputs":[],"source":["# Define convolutional layer\n","conv = nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(2,2), stride=(1,1)).to(device)\n","x = torch.tensor([[[[1.,2,2,1],[2,1,1,2],[3,4,4,3],[4,3,3,4]]]]).to(device)\n","conv.weight = torch.nn.Parameter(torch.tensor([[[[1,1],[1,1]]]],dtype=torch.float).to(device))\n","conv.bias = torch.nn.Parameter(torch.zeros(1).to(device))\n","y= conv(x)\n","x = x.cpu().detach().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')"]},{"cell_type":"code","execution_count":null,"id":"b3ccd008-7b35-4b93-9131-861c41bbdd71","metadata":{"id":"b3ccd008-7b35-4b93-9131-861c41bbdd71"},"outputs":[],"source":["# Define convolutional layer\n","conv = nn.Conv2d(in_channels=3,out_channels=8,kernel_size=5)\n","x = torch.rand(64,3,224,224).to(torch.float)\n","y = conv(x)\n","\n","print(list(x.shape),list(y.shape),sep='\\n')"]},{"cell_type":"markdown","id":"ee39987b-9032-4fa7-be4f-cbfc6ef4dac5","metadata":{"id":"ee39987b-9032-4fa7-be4f-cbfc6ef4dac5"},"source":["## Batch Normalization layer\n","\n","<div style=\"text-align: justify\">\n","Batch normalization is a crucial operation in Convolutional Neural Networks (CNNs) that addresses the internal covariate shift problem during training. It normalizes the activations of each layer by subtracting the batch mean and dividing by the batch standard deviation, followed by scaling with learnable parameters. This normalization ensures that the input distribution to each layer remains stable throughout training, which accelerates convergence and improves the model's generalization ability. By reducing internal covariate shift, batch normalization allows for more stable gradients during backpropagation, mitigating issues like vanishing or exploding gradients. Moreover, it acts as a form of regularization, reducing the reliance on dropout and enabling the use of higher learning rates without risking instability. Batch normalization also exhibits a slight regularization effect by introducing noise during training, which helps prevent overfitting. Overall, batch normalization is an essential component in CNNs, contributing to faster training, improved convergence, and enhanced model performance. A well known normalization is given as follows\n","</div>\n","$$\n","O = \\frac{{I - \\mu(I)}}{{\\sigma(I)}}\n","$$\n"]},{"cell_type":"code","execution_count":null,"id":"55eaded3-5abc-40ab-858d-852383aa883f","metadata":{"id":"55eaded3-5abc-40ab-858d-852383aa883f"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","np.set_printoptions(suppress=True,precision=4)\n","\n","# Define BatchNorm layer\n","batch = nn.BatchNorm2d(1).to(device)\n","x = torch.tensor([[[[1.,2,3],[4,5,6],[7,8,9]]]]).to(device)\n","y = torch.round(batch(x),decimals=4)\n","x = x.detach().cpu().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Original Output: {y}',sep='\\n\\n',end='\\n\\n')\n","q = np.round((x-x.mean())/x.std(),decimals=4)\n","print('Calculated Output: ',q,end='\\n\\n')\n","print(f'Details: Mean,std,std: {x.mean():0.4f},{(sum([(i.item()-x.mean())**2 for i in x.reshape(-1)])/9)**0.5:0.4f},{x.std().item():0.4f}')\n","print(f'Output[2,2] manual calcualtion: {(9-5)/2.582:0.4f}')"]},{"cell_type":"markdown","id":"88cceebd-6bfa-4207-a5fb-160b8ea7b5b8","metadata":{"id":"88cceebd-6bfa-4207-a5fb-160b8ea7b5b8"},"source":["## Dropout layer\n","\n","<div style=\"text-align: justify\">\n","Dropout is a regularization technique in neural networks, randomly deactivating a proportion of neurons during training to prevent overfitting. It enhances model generalization by reducing dependency on specific neurons, thus improving robustness and preventing co-adaptation of neurons.\n","</div>\n"]},{"cell_type":"code","execution_count":null,"id":"e8db4d99-a541-4cff-a3f7-b9e5dd87f9be","metadata":{"id":"e8db4d99-a541-4cff-a3f7-b9e5dd87f9be"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","np.set_printoptions(suppress=True,precision=4)\n","\n","# Define BatchNorm layer\n","drop = nn.Dropout(0.5).to(device)\n","x = torch.tensor([[1.,2],[3,4]]).to(device)\n","y = drop(x)\n","x = x.cpu().detach().numpy()\n","y = y.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n')"]},{"cell_type":"markdown","id":"de945a5c-3450-4036-8435-0f45af25c0dc","metadata":{"id":"de945a5c-3450-4036-8435-0f45af25c0dc"},"source":["# Activation Function\n","\n","<div style=\"text-align: justify\">\n","In a Convolutional Neural Network (CNN), an activation function is like a gatekeeper that decides whether a neuron should be activated or not based on the input it receives. Imagine a switch: if the input is strong enough, the switch flips on and lets the information pass through; if not, it stays off and blocks the information.<br>\n","The purpose of an activation function is to introduce non-linearity into the network. Without it, the CNN would be limited to linear transformations, making it less capable of learning complex patterns in data like images, sounds, or texts. Non-linear activation functions enable the network to learn and represent more intricate relationships between inputs and outputs.<br>\n","Overall, activation functions play a crucial role in empowering CNNs to understand and interpret complex data, making them essential components in deep learning architectures.\n","</div>"]},{"cell_type":"markdown","id":"77176a42-f9cc-4fda-a602-0e6a0224e95f","metadata":{"id":"77176a42-f9cc-4fda-a602-0e6a0224e95f"},"source":["## Some common Activation Function"]},{"cell_type":"markdown","id":"df100c7d-6fc7-4dfe-91b2-f3c7dead69a7","metadata":{"id":"df100c7d-6fc7-4dfe-91b2-f3c7dead69a7"},"source":["<div style=\"text-align: justify\">\n","<b>ReLU:</b> ReLU (Rectified Linear Unit) turns on for positive inputs, outputting the same value, and turns off for negative inputs, outputting zero.<br>\n","$$\n","f(x) = \\begin{cases}\n","x, & \\text{if } x \\geq 0 \\\\\n","0, & \\text{elsewhere}\n","\\end{cases}\n","$$\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"9f864c0b-4f33-4d62-aabf-15ec3d925b3c","metadata":{"id":"9f864c0b-4f33-4d62-aabf-15ec3d925b3c"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","\n","relu = nn.ReLU().to(device)\n","x = torch.tensor([-0.25,0,0.25,-2,2]).to(device)\n","y = torch.round(relu(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","x = torch.tensor([[-0.25,0,0.25,-2,2],[-3,3,-4,4,-5]]).to(device)\n","y = torch.round(relu(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n')"]},{"cell_type":"markdown","id":"7a107629-1efc-43c2-9410-c8b8ed3eb369","metadata":{"id":"7a107629-1efc-43c2-9410-c8b8ed3eb369"},"source":["<div style=\"text-align: justify\">\n","<b>LeakyReLU:</b> Sometimes in ReLU, neurons can get stuck in a state where they always output zero for any input, which is called the \"dying ReLU\" problem. Leaky ReLU solves this by allowing a small, non-zero gradient for negative inputs, ensuring that even if a neuron's output is consistently negative, it can still learn and adjust.<br>\n","$$\n","f(x) = \\begin{cases}\n","x, & \\text{if } x \\geq 0 \\\\\n","\\alpha x, & \\text{elsewhere}\n","\\end{cases}\n","$$\n","where $\\alpha$ is a very small positive constant.\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"2e18f192-7ca6-482f-91a6-fbf547537b4a","metadata":{"id":"2e18f192-7ca6-482f-91a6-fbf547537b4a"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","np.set_printoptions(suppress=True,precision=4)\n","\n","lrelu = nn.LeakyReLU(0.001).to(device)\n","x = torch.tensor([-0.25,0,0.25,-2,2]).to(device)\n","y = torch.round(lrelu(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","x = torch.tensor([[-0.25,0,0.25,-2,2],[-3,3,-4,4,-5]]).to(device)\n","y = torch.round(lrelu(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n')"]},{"cell_type":"markdown","id":"82413d64-2bae-4696-b483-82550ed04836","metadata":{"id":"82413d64-2bae-4696-b483-82550ed04836"},"source":["<div style=\"text-align: justify\">\n","<b>ELU:</b> Exponential Linear Unit (ELU) introduces a saturation regime for negative inputs, allowing negative values which can help with learning dynamics.<br>\n","$$\n","f(x) = \\begin{cases}\n","x, & \\text{if } x \\geq 0 \\\\\n","\\alpha \\left(e^x-1\\right), & \\text{elsewhere}\n","\\end{cases}\n","$$\n","where $\\alpha$ is a constant which generally considered as 1.\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"e732e383-390c-467f-8b73-f80cc33886d4","metadata":{"id":"e732e383-390c-467f-8b73-f80cc33886d4"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","np.set_printoptions(suppress=True,precision=4)\n","\n","elu = nn.ELU().to(device)\n","x = torch.tensor([-0.25,0,0.25,-2,2]).to(device)\n","y = torch.round(elu(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","x = torch.tensor([[-0.25,0,0.25,-2,2],[-3,3,-4,4,-5]]).to(device)\n","y = torch.round(elu(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n')"]},{"cell_type":"markdown","id":"bc5e1d59-c003-4a53-a11e-a45c88dfa684","metadata":{"id":"bc5e1d59-c003-4a53-a11e-a45c88dfa684"},"source":["<div style=\"text-align: justify\">\n","<b>GELU:</b> Gaussian Error Linear Unit (GELU) is a smooth approximation of the rectifier function, which is claimed to perform well in deep learning tasks.<br>\n","$$\n","f(x) = 0.5x\\left(1+erf\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)\n","$$\n","where erf is error random function.\n","</div>"]},{"cell_type":"markdown","id":"9848dc29-e36a-40c1-aeb2-8dd693c09f76","metadata":{"id":"9848dc29-e36a-40c1-aeb2-8dd693c09f76"},"source":["<div style=\"text-align: justify\">\n","<b>Linear:</b> The linear activation function is one of the simplest activation functions used in neural networks. It's often used in the output layer of a neural network for tasks where the output is unconstrained, such as regression problems where the target variable can take on any real value.<br>\n","$$\n","f(x) = x\n","$$\n","In this function, the output $f(x)$ is simply equal to the input x. This means that the output of the neuron is directly proportional to its input.<br>\n","One of the key properties of the linear activation function is that it preserves the scale of the input. In other words, if you increase the input by a certain amount, the output will also increase by the same amount. This property makes it suitable for regression tasks where the goal is to predict continuous values.<br>\n","However, one drawback of the linear activation function is that it's not suitable for deeper neural networks or tasks involving classification. This is because linear activation functions result in linear combinations of inputs, which limits the model's ability to learn complex patterns in the data. In deeper networks, using linear activation functions can lead to the model being too simplistic and unable to capture non-linear relationships in the data.\n","</div>"]},{"cell_type":"markdown","id":"ebfc162c-7c05-46eb-b508-8e2f742fbed9","metadata":{"id":"ebfc162c-7c05-46eb-b508-8e2f742fbed9"},"source":["<div style=\"text-align: justify\">\n","<b>Sigmoid:</b> Sigmoid squashes the input to the range $\\left(0,1\\right)$. It's commonly used in the output layer of a binary classification problem.<br>\n","$$\n","f(x) = \\frac{1}{1+e^{-x}}\n","$$\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"05d2ffbb-4655-4f54-a7c0-03c874c17028","metadata":{"id":"05d2ffbb-4655-4f54-a7c0-03c874c17028"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","np.set_printoptions(suppress=True,precision=4)\n","\n","sigmoid = nn.Sigmoid().to(device)\n","x = torch.tensor([-0.25,0,0.25,-2,2]).to(device)\n","y = torch.round(sigmoid(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","x = torch.tensor([[-0.25,0,0.25,-2,2],[-3,3,-4,4,-5]]).to(device)\n","y = torch.round(sigmoid(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n')"]},{"cell_type":"markdown","id":"4da01c78-c1e9-4111-96d3-540bae6eb0c1","metadata":{"id":"4da01c78-c1e9-4111-96d3-540bae6eb0c1"},"source":["<div style=\"text-align: justify\">\n","<b>Softmax:</b> Softmax is indeed a crucial non-linear activation function, commonly used in the output layer of neural networks for multi-class classification tasks. It shows the output probability for each class. You can use it according to any dimention.<br>\n","<i>N.B.</i> Remember not to use this at the last layer while using as pytorch nn module and if CategoricalCrosEntroy loss is used. Because this loss function by default apply it before calculation. So, if you use it the Softmax will be applied twice which will cause abnormality in output.\n","$$\n","f(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{N}e^{x_j}}\n","$$\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"365ed6ee","metadata":{"id":"365ed6ee"},"outputs":[],"source":["torch.set_printoptions(precision=4)\n","np.set_printoptions(suppress=True,precision=4)\n","\n","softmax = nn.Softmax(dim=0).to(device)\n","x = torch.tensor([-0.25,0,0.25,-2,2]).to(device)\n","y = torch.round(softmax(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output: {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","x = torch.tensor([[-0.25,0,0.25,-2,2],[-3,3,-4,4,-5]]).to(device)\n","y = torch.round(softmax(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output (dim=0): {y}',sep='\\n\\n',end='\\n\\n\\n\\n')\n","softmax = nn.Softmax(dim=1).to(device)\n","x = torch.tensor([[-0.25,0,0.25,-2,2],[-3,3,-4,4,-5]]).to(device)\n","y = torch.round(softmax(x),decimals=4).cpu().detach().numpy()\n","x = x.cpu().detach().numpy()\n","print(f'Input: {x}',f'Output (dim=1): {y}',sep='\\n\\n')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}